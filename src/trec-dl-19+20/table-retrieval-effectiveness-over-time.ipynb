{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d23fb058-55c9-4a69-9c1f-c91a29416a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table table-retrieval-effectiveness-over-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87009ed1-3ced-469f-b0dd-01f014e3268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install trectools\n",
    "\n",
    "from trectools import TrecQrel, TrecRun, TrecEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8954b4ef-6e48-407d-bc56-642b46d8fe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_DIR_MARCO='/mnt/ceph/storage/data-in-progress/data-teaching/theses/wstud-thesis-probst/retrievalExperiments/runs-ecir22/dl19+20/'\n",
    "\n",
    "QRELS_MARCO_DL_19=TrecQrel('../../Data/dl19+20/2019qrels-docs.txt')\n",
    "QRELS_MARCO_DL_20=TrecQrel('../../Data/dl19+20/2020qrels-docs.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9686cd2c-44e4-4688-9ec9-e8512864db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "APPROACH_TO_MARCO_V1_RUN_FILE={\n",
    "    'BM25@2016-07': 'run.cc-16-07-anchortext.bm25-default.txt',\n",
    "    'BM25@2017-04': 'run.cc-17-04-anchortext.bm25-default.txt',\n",
    "    'BM25@2018-13': 'run.cc-18-13-anchortext.bm25-default.txt',\n",
    "    'BM25@2019-47': 'run.cc-19-47-anchortext.bm25-default.txt',\n",
    "    'BM25@2020-05': 'run.cc-20-05-anchortext.bm25-default.txt',\n",
    "    'BM25@2021-04': 'run.cc-21-04-anchortext.bm25-default.txt',\n",
    "    'BM25@16--21': 'run.cc-combined-anchortext.bm25-default.txt',\n",
    "    'BM25@Content': 'run.ms-marco-content.bm25-default.txt',\n",
    "    'BM25@Orcas': 'run.orcas.bm25-default.txt',\n",
    "    'DeepCT@Anchor': 'run.ms-marco-deepct-v1-anserini-docs-cc-2019-47-sampled-test-overlap-removed-389979.bm25-default.txt',\n",
    "    'DeepCT@Orcas': 'run.ms-marco-deepct-v1-anserini-docs-orcas-sampled-test-overlap-removed-390009.bm25-default.txt',\n",
    "    'DeepCT@Train':'run.ms-marco-deepct-v1-anserini-docs-ms-marco-training-set-test-overlap-removed-389973.bm25-default.txt',\n",
    "    'MonoT5': 'run.ms-marco-content.bm25-mono-t5-maxp.txt',\n",
    "    'MonoBERT': 'run.ms-marco-content.bm25-mono-bert-maxp.txt',\n",
    "    'LambdaMART@CTA':'run.ms-marco.lambda-mart-cta-trees-1000.txt',\n",
    "    'LambdaMART@CTOA':'run.ms-marco.lambda-mart-ctoa-trees-1000.txt',\n",
    "    'LambdaMART@CTO':'run.ms-marco.lambda-mart-cto-trees-1000.txt',\n",
    "    'LambdaMART@CT':'run.ms-marco.lambda-mart-ct-trees-1000.txt',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19b380d0-29b1-41bb-8356-315e43582663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table*}[bt]\n",
      "    \\setlength{\\tabcolsep}{0.18em}\n",
      "    \\caption{TBD.}\n",
      "    \\label{table-retrieval-effectiveness-over-time}\n",
      "    \\scriptsize\n",
      "    \\begin{minipage}{0.4\\textwidth}\n",
      "    \\scriptsize\n",
      "    (a) TBD.\\\\\n",
      "    \\includegraphics[width=1\\textwidth]{figure-retrieval-effectiveness-over-time}\n",
      "    \\end{minipage}%\n",
      "    \\hfill\n",
      "    \\begin{tabular*}{0.6\\textwidth}{@{\\extracolsep{\\fill}}ll@{\\quad}ccc@{\\quad}ccc@{}}\n",
      "        \\multicolumn{3}{@{}l@{}}{(b) TBD.}\\\\\n",
      "        \\toprule\n",
      "\n",
      "        & & \\multicolumn{2}{@{}c@{\\quad}}{DL 2019} & \\multicolumn{2}{@{}c@{\\quad}}{DL 2020}\\\\\n",
      "\n",
      "        \\cmidrule(r{1em}){3-4} \\cmidrule(r{1em}){5-6}\n",
      "\n",
      "        & & nDCG@10 & nDCG@20 & nDCG@10 & nDCG@20\\\\\n",
      "\n",
      "        \\midrule\n",
      "\n",
      "        \\multirow{7}{*}{\\rotatebox[origin=c]{90}{\\parbox[c]{4em}{\\centering \\textbf{Anchor}}}}\n",
      "        & BM25@2016-07 & 0.37& 0.32& 0.28& 0.24 \\\\\n",
      "        \n",
      "        & BM25@2017-04 & 0.39& 0.35& 0.29& 0.27 \\\\\n",
      "\n",
      "        & BM25@2018-13 & 0.35& 0.33& 0.27& 0.25 \\\\\n",
      "\n",
      "        & BM25@2019-47 & 0.34& 0.31& 0.27& 0.25 \\\\\n",
      "\n",
      "        & BM25@2020-05 & 0.38& 0.35& 0.30& 0.28 \\\\\n",
      "\n",
      "        & BM25@2021-04 & 0.35& 0.32& 0.30& 0.26 \\\\\n",
      "        \n",
      "        & BM25@16--21 & {\\textbf{0.41}} & {\\textbf{0.38}} & {\\textbf{0.34}} & {\\textbf{0.32}}  \\\\\n",
      "\n",
      "        \\midrule\n",
      "\n",
      "        \\multirow{7}{*}{\\rotatebox[origin=c]{90}{\\parbox[c]{4em}{\\centering \\textbf{Baselines}}}}\n",
      "        & BM25@Content & 0.51& 0.50& 0.53& 0.53 \\\\\n",
      "\n",
      "        & BM25@Orcas & 0.45& 0.41& 0.36& 0.33 \\\\\n",
      "        \n",
      "        & DeepCT@Anchor & 0.53& 0.54& 0.55& 0.53 \\\\\n",
      "\n",
      "        & DeepCT@Orcas & 0.52& 0.53& 0.54& 0.54 \\\\\n",
      "\n",
      "        & DeepCT@Train & 0.54& 0.53& 0.51& 0.52 \\\\\n",
      "        \n",
      "        & MonoT5 & {\\textbf{0.68}} & {\\textbf{0.64}} & {\\textbf{0.62}} & {\\textbf{0.63}}  \\\\\n",
      "        \n",
      "        & MonoBERT & 0.67& {\\textbf{0.63}} & {\\textbf{0.63}} & {\\textbf{0.62}}  \\\\\n",
      "\n",
      "        & LambdaMART@CTOA & 0.59& 0.55& 0.57& 0.57 \\\\\n",
      "        \n",
      "        & LambdaMART@CTO & 0.57& 0.55& 0.57& 0.58 \\\\\n",
      "        \n",
      "        & LambdaMART@CTA & 0.57& 0.54& 0.57& 0.57 \\\\\n",
      "        \n",
      "        & LambdaMART@CT & 0.57& 0.55& 0.56& 0.56 \\\\\n",
      "\n",
      "        \\bottomrule\n",
      "\n",
      "    \\end{tabular*}\n",
      "    \\vspace*{-2ex}\n",
      "\\end{table*}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def is_anchor_text(run_file):\n",
    "    return '-anchortext' in run_file\n",
    "\n",
    "def format_score(score, run_file, position):\n",
    "    # Manually maintained\n",
    "    if is_anchor_text(run_file):\n",
    "        max_scores = [0.40, 0.37, 0.33, 0.31]\n",
    "    else:\n",
    "        max_scores = [0.67, 0.63, 0.61, 0.62]\n",
    "        \n",
    "    ret = '{:.2f}'.format(score)\n",
    "    if max_scores[position] <= score:\n",
    "        return '{\\\\textbf{' + ret + '}} '\n",
    "    else:\n",
    "        return ret\n",
    "\n",
    "def eval_on_marco_dl19(run_file):\n",
    "    ret = ' '\n",
    "    \n",
    "    run = TrecRun(RUN_DIR_MARCO + '/' + run_file)\n",
    "    run.run_data = run.run_data[run.run_data['query'].isin(QRELS_MARCO_DL_19.qrels_data['query'].unique())]\n",
    "    trec_eval=TrecEval(run, QRELS_MARCO_DL_19)\n",
    "    \n",
    "    ret += '& ' + format_score(trec_eval.get_ndcg(depth=10, removeUnjudged=True), run_file, 0)\n",
    "    ret += '& ' + format_score(trec_eval.get_ndcg(depth=20, removeUnjudged=True), run_file, 1)\n",
    "    \n",
    "    return ret + '&'\n",
    "\n",
    "def eval_on_marco_dl20(run_file):\n",
    "    ret = ' '\n",
    "    \n",
    "    run = TrecRun(RUN_DIR_MARCO + '/' + run_file)\n",
    "    run.run_data = run.run_data[run.run_data['query'].isin(QRELS_MARCO_DL_20.qrels_data['query'].unique())]\n",
    "    trec_eval=TrecEval(run, QRELS_MARCO_DL_20)\n",
    "    \n",
    "    ret += format_score(trec_eval.get_ndcg(depth=10, removeUnjudged=True), run_file, 2)\n",
    "    ret += '& ' + format_score(trec_eval.get_ndcg(depth=20, removeUnjudged=True), run_file, 3)\n",
    "    \n",
    "    return ret\n",
    "\n",
    "def table_row(approach):\n",
    "    v1_eval = ' & --- & --- &'\n",
    "    \n",
    "    if approach in APPROACH_TO_MARCO_V1_RUN_FILE:\n",
    "        v1_eval = eval_on_marco_dl19(APPROACH_TO_MARCO_V1_RUN_FILE[approach])\n",
    "    \n",
    "    v2_eval = ' --- & ---'\n",
    "    \n",
    "    if approach in APPROACH_TO_MARCO_V1_RUN_FILE:\n",
    "        v2_eval = eval_on_marco_dl20(APPROACH_TO_MARCO_V1_RUN_FILE[approach])\n",
    "    \n",
    "    return '& ' + approach + v1_eval + v2_eval + ' \\\\\\\\'\n",
    "\n",
    "\n",
    "def table_entry_page_retrieval_effectiveness():\n",
    "    return '''\\\\begin{table*}[bt]\n",
    "    \\\\setlength{\\\\tabcolsep}{0.18em}\n",
    "    \\\\caption{TBD.}\n",
    "    \\\\label{table-retrieval-effectiveness-over-time}\n",
    "    \\\\scriptsize\n",
    "    \\\\begin{minipage}{0.4\\\\textwidth}\n",
    "    \\\\scriptsize\n",
    "    (a) TBD.\\\\\\\\\n",
    "    \\\\includegraphics[width=1\\\\textwidth]{figure-retrieval-effectiveness-over-time}\n",
    "    \\\\end{minipage}%\n",
    "    \\\\hfill\n",
    "    \\\\begin{tabular*}{0.6\\\\textwidth}{@{\\\\extracolsep{\\\\fill}}ll@{\\\\quad}ccc@{\\\\quad}ccc@{}}\n",
    "        \\\\multicolumn{3}{@{}l@{}}{(b) TBD.}\\\\\\\\\n",
    "        \\\\toprule\n",
    "\n",
    "        & & \\\\multicolumn{2}{@{}c@{\\\\quad}}{DL 2019} & \\\\multicolumn{2}{@{}c@{\\\\quad}}{DL 2020}\\\\\\\\\n",
    "\n",
    "        \\\\cmidrule(r{1em}){3-4} \\\\cmidrule(r{1em}){5-6}\n",
    "\n",
    "        & & nDCG@10 & nDCG@20 & nDCG@10 & nDCG@20\\\\\\\\\n",
    "\n",
    "        \\\\midrule\n",
    "\n",
    "        \\\\multirow{7}{*}{\\\\rotatebox[origin=c]{90}{\\\\parbox[c]{4em}{\\\\centering \\\\textbf{Anchor}}}}\n",
    "        ''' + table_row('BM25@2016-07') + '''\n",
    "        \n",
    "        ''' + table_row('BM25@2017-04') + '''\n",
    "\n",
    "        ''' + table_row('BM25@2018-13') + '''\n",
    "\n",
    "        ''' + table_row('BM25@2019-47') + '''\n",
    "\n",
    "        ''' + table_row('BM25@2020-05') + '''\n",
    "\n",
    "        ''' + table_row('BM25@2021-04') + '''\n",
    "        \n",
    "        ''' + table_row('BM25@16--21') + '''\n",
    "\n",
    "        \\\\midrule\n",
    "\n",
    "        \\\\multirow{7}{*}{\\\\rotatebox[origin=c]{90}{\\\\parbox[c]{4em}{\\\\centering \\\\textbf{Baselines}}}}\n",
    "        ''' + table_row('BM25@Content') + '''\n",
    "\n",
    "        ''' + table_row('BM25@Orcas') + '''\n",
    "        \n",
    "        ''' + table_row('DeepCT@Anchor') + '''\n",
    "\n",
    "        ''' + table_row('DeepCT@Orcas') + '''\n",
    "\n",
    "        ''' + table_row('DeepCT@Train') + '''\n",
    "        \n",
    "        ''' + table_row('MonoT5') + '''\n",
    "        \n",
    "        ''' + table_row('MonoBERT') + '''\n",
    "\n",
    "        ''' + table_row('LambdaMART@CTOA') + '''\n",
    "        \n",
    "        ''' + table_row('LambdaMART@CTO') + '''\n",
    "        \n",
    "        ''' + table_row('LambdaMART@CTA') + '''\n",
    "        \n",
    "        ''' + table_row('LambdaMART@CT') + '''\n",
    "\n",
    "        \\\\bottomrule\n",
    "\n",
    "    \\\\end{tabular*}\n",
    "    \\\\vspace*{-2ex}\n",
    "\\\\end{table*}\n",
    "'''\n",
    "\n",
    "print(table_entry_page_retrieval_effectiveness())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
